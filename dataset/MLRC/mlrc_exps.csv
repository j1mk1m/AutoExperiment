paper_id,exp_id,description,result,func_dependencies,solution
2303.11932,0,"Train a model on VOC2007 dataset with bcos as the model backbone, BCos attribution method, Energy localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.0011178854996824856}","0,4,5,6,7,8,9,10",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn Energy --attribution_method BCos --optimize_explanations
2303.11932,1,"Train a model on VOC2007 dataset with bcos as the model backbone, GradCam attribution method, Energy localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.08365939805298694}","0,4,5,6,7,8,11,12",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn Energy --attribution_method GradCam --optimize_explanations
2303.11932,2,"Train a model on VOC2007 dataset with bcos as the model backbone, IxG attribution method, Energy localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.0012173376492053368}","0,4,5,6,7,8,9,13,14",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn Energy --attribution_method IxG --optimize_explanations
2303.11932,3,"Train a model on VOC2007 dataset with bcos as the model backbone, BCos attribution method, L1 localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.0011172918019814787}","3,4,5,6,7,8,9,10",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn L1 --attribution_method BCos --optimize_explanations
2303.11932,4,"Train a model on VOC2007 dataset with bcos as the model backbone, BCos attribution method, PPCE localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.0011075028636673195}","2,4,5,6,7,8,9,10",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn PPCE --attribution_method BCos --optimize_explanations
2303.11932,5,"Train a model on VOC2007 dataset with bcos as the model backbone, BCos attribution method, RRR localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.0010461464868664432}","1,4,5,6,7,8,9,10",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn RRR --attribution_method BCos --optimize_explanations
2303.11932,6,"Train a model on VOC2007 dataset with bcos as the model backbone, GradCam attribution method, L1 localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.08383034744334648}","3,4,5,6,7,8,11,12",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn L1 --attribution_method GradCam --optimize_explanations
2303.11932,7,"Train a model on VOC2007 dataset with bcos as the model backbone, GradCam attribution method, PPCE localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.0834082679933393}","2,4,5,6,7,8,11,12",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn PPCE --attribution_method GradCam --optimize_explanations
2303.11932,8,"Train a model on VOC2007 dataset with bcos as the model backbone, GradCam attribution method, RRR localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.08362105198746296}","1,4,5,6,7,8,11,12",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn RRR --attribution_method GradCam --optimize_explanations
2303.11932,9,"Train a model on VOC2007 dataset with bcos as the model backbone, IxG attribution method, L1 localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.0012328967245244153}","3,4,5,6,7,8,13,14",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn L1 --attribution_method IxG --optimize_explanations
2303.11932,10,"Train a model on VOC2007 dataset with bcos as the model backbone, IxG attribution method, PPCE localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.0011984381446661875}","2,4,5,6,7,8,13,14",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn PPCE --attribution_method IxG --optimize_explanations
2303.11932,11,"Train a model on VOC2007 dataset with bcos as the model backbone, IxG attribution method, RRR localization loss, and optimizing explanations. Return the IoU after training for 1 epoch in this format {""IoU"": 0.0}. Replace 0.0 with the actual value.","{""IoU"": 0.0012248501415785702}","1,4,5,6,7,8,13,14",python train.py --dataset VOC2007 --model_backbone bcos --total_epochs 1 --localization_loss_fn RRR --attribution_method IxG --optimize_explanations
2309.05569,0,"Train a ITI-GEN model on CelebA dataset with a single attribute, 5 o'clock shadow. Train for 5 epochs with default parameters. Then, generate 4 positive and 4 negative images with 1 iteration for the 5 o'clock shadow attribute, using stable diffusion model weights as checkpoint and using the prompt-path from training. Evaluate the generated images and return the FID score in this format {""FID score"": 0.0}. Replace 0.0 with the actual value.","{""FID score"": 202.57}","0,1,2,3,4,5,6,7,8,9","bash jobfiles/celeba_single/iti_gen/train/5_o_Clock_Shadow.sh
python generation.py \
    --config=""models/sd/configs/stable-diffusion/v1-inference.yaml"" \
    --ckpt=""models/sd/models/ldm/stable-diffusion-v1/model.ckpt"" \
    --plms \
    --attr-list=""5_o_Clock_Shadow"" \
    --outdir=""results/celeba_single/iti_gen/5_o_Clock_Shadow"" \
    --prompt-path=""ckpts/a_headshot_of_a_person_5_o_Clock_Shadow/original_prompt_embedding/basis_final_embed_4.pt"" \
    --skip_grid \
    --n_iter=1 \
    --n_samples=4 \
    --seed=0
bash jobfiles/celeba_single/iti_gen/evaluation/5_o_Clock_Shadow.sh"
2309.05569,1,"Train a ITI-GEN model on CelebA dataset with a single attribute, high cheekbones. Train for 5 epochs with default parameters. Then, generate 4 positive and 4 negative images with 1 iteration for the high cheekbones attribute, using stable diffusion model weights as checkpoint and using the prompt-path from training. Use seed 19. Evaluate the generated images and return the FID score in this format {""FID score"": 0.0}. Replace 0.0 with the actual value.","{""FID score"": 243.83}","0,1,2,3,4,5,6,7,8,9","bash jobfiles/celeba_single/iti_gen/train/High_Cheekbones.sh
python generation.py \
    --config=""models/sd/configs/stable-diffusion/v1-inference.yaml"" \
    --ckpt=""models/sd/models/ldm/stable-diffusion-v1/model.ckpt"" \
    --plms \
    --attr-list=""High_Cheekbones"" \
    --outdir=""results/celeba_single/iti_gen/High_Cheekbones"" \
    --prompt-path=""ckpts/a_headshot_of_a_person_High_Cheekbones/original_prompt_embedding/basis_final_embed_4.pt"" \
    --skip_grid \
    --n_iter=1 \
    --n_samples=4 \
    --seed=19
bash jobfiles/celeba_single/iti_gen/evaluation/High_Cheekbones.sh"
2309.05569,2,"Train a ITI-GEN model on CelebA dataset with a single attribute, bangs. Train for 5 epochs with default parameters. Return total loss in the last step of last epoch in this format {""total loss"": 0.0}. Replace 0.0 with the actual value.","{""total loss"": 0.36406}","0,1,2,3,4,5,6,7,8,9",bash jobfiles/celeba_single/iti_gen/train/Bangs.sh
2309.05569,3,"Train a ITI-GEN model on CelebA dataset with a single attribute, chubby. Train for 5 epochs with default parameters. Return total loss in the last step of last epoch in this format {""total loss"": 0.0}. Replace 0.0 with the actual value.","{""total loss"": 0.31316}","0,1,2,3,4,5,6,7,8,9",bash jobfiles/celeba_single/iti_gen/train/Chubby.sh
2309.05569,4,"Train a ITI-GEN model on CelebA dataset with a single attribute, smiling. Train for 5 epochs with default parameters. Return total loss in the last step of last epoch in this format {""total loss"": 0.0}. Replace 0.0 with the actual value.","{""total loss"": 0.57191}","0,1,2,3,4,5,6,7,8,9",bash jobfiles/celeba_single/iti_gen/train/Smiling.sh
2309.05569,5,"Train a ITI-GEN model on CelebA dataset with a single attribute, sideburns. Train for 5 epochs with default parameters. Return total loss in the last step of last epoch in this format {""total loss"": 0.0}. Replace 0.0 with the actual value.","{""total loss"": 0.27687}","0,1,2,3,4,5,6,7,8,9",bash jobfiles/celeba_single/iti_gen/train/Sideburns.sh
2309.05569,6,"Train a ITI-GEN model on CelebA dataset with a 2 attributes, male and young. Train for 5 epochs with default parameters. Return the total loss in the last step of last epoch for young attribute in this format {""total loss"": 0.0}. Replace 0.0 with the actual value.","{""total loss"": 0.46946}","0,1,2,3,4,5,6,7,8,9",bash jobfiles/celeba_multi/2/iti_gen/train/Male_Young.sh
2309.05569,7,"Train a ITI-GEN model on CelebA dataset with a 2 attributes, male and young. Train for 5 epochs with default parameters. Then, generate 4 positive and 4 negative images with 1 iteration, using stable diffusion model weights as checkpoint and using the prompt-path from training. Use seed 0. Evaluate the generated images and return the FID score in this format {""FID score"": 0.0}. Replace 0.0 with the actual value.","{""FID score"": 198.26}","0,1,2,3,4,5,6,7,8,9","bash jobfiles/celeba_multi/2/iti_gen/train/Male_Young.sh
python generation.py \
    --config=""models/sd/configs/stable-diffusion/v1-inference.yaml"" \
    --ckpt=""models/sd/models/ldm/stable-diffusion-v1/model.ckpt"" \
    --plms \
    --attr-list=""Male,Young"" \
    --outdir=""results/celeba_multi/2/iti_gen/Male_Young"" \
    --prompt-path=""ckpts/a_headshot_of_a_person_Male_Young/original_prompt_embedding/basis_final_embed_4.pt"" \
    --skip_grid \
    --n_iter=1 \
    --n_samples=4 \
    --seed=0
bash jobfiles/celeba_multi/2/iti_gen/evaluation/Male_Young.sh"
2309.05569,8,"Train a ITI-GEN model on CelebA dataset with a 3 attributes, male, young, and with eyeglasses.Train for 5 epochs with default parameters. Return the total loss in the last step of last epoch for Eyeglasses attribute in this format {""total loss"": 0.0}. Replace 0.0 with the actual value.","{""total loss"": 0.40459}","0,1,2,3,4,5,6,7,8,9",bash jobfiles/celeba_multi/3/iti_gen/train/Male_Young_Eyeglasses.sh
2309.05569,9,"Train a ITI-GEN model on CelebA dataset with a 4 attributes, male, young, eyeglasses, and smiling. Train for 5 epochs with default parameters. Return the total loss in the last step of last epoch for Smiling attribute in this format {""total loss"": 0.0}. Replace 0.0 with the actual value.","{""total loss"": 0.62732}","0,1,2,3,4,5,6,7,8,9",bash jobfiles/celeba_multi/4/iti_gen/train/Male_Young_Eyeglasses_Smiling.sh
2205.00048,0,"Run the experiment on movielens dataset with POP model, stochastic conduct, using gender as group label, and on 1 datapoint. Return all metrics in format {""IIF"": [0.0], ""IGF"": [0.0], ""GIF"": [0.0], ""GGF"": [0.0], ""AIF"": [0.0], ""AGF"": [0.0], ""IID"": [0.0], ""IGD"": [0.0], ""GID"": [0.0], ""GGD"": [0.0], ""AID"": [0.0], ""AGD"": [0.0], ""IIR"": [0.0], ""IGR"": [0.0], ""GIR"": [0.0], ""GGR"": [0.0], ""AIR"": [0.0], ""AGR"": [0.0]} (replace 0.0 with real values)","{'IIF': [0.00022957766970338144], 'IGF': [6.531420796327108e-06], 'GIF': [1.5155270864260923e-05], 'GGF': [5.865956097793335e-07], 'AIF': [1.3747849386984705e-05], 'AGF': [3.417965144382433e-07], 'IID': [0.00012941373053020611], 'IGD': [2.6309788544084347e-06], 'GID': [2.9055386641092446e-05], 'GGD': [1.5267569462768894e-06], 'AID': [2.832898259643734e-05], 'AGD': [1.471852226331411e-06], 'IIR': [3.843119017823239e-06], 'IGR': [8.527492939359041e-07], 'GIR': [1.9742164624446923e-05], 'GGR': [1.501924858720956e-06], 'AIR': [2.031354493845111e-05], 'AGR': [1.693986814130217e-06]}","0,1,2,3,4,5,6",python src/run_metric.py --ndatapoints 1 --conduct sh --model Pop --age N
2205.00048,1,"Run the experiment on movielens dataset with POP model, stochastic conduct, using age as group label, and on 1 datapoint. Return all metrics in format {""IIF"": [0.0], ""IGF"": [0.0], ""GIF"": [0.0], ""GGF"": [0.0], ""AIF"": [0.0], ""AGF"": [0.0], ""IID"": [0.0], ""IGD"": [0.0], ""GID"": [0.0], ""GGD"": [0.0], ""AID"": [0.0], ""AGD"": [0.0], ""IIR"": [0.0], ""IGR"": [0.0], ""GIR"": [0.0], ""GGR"": [0.0], ""AIR"": [0.0], ""AGR"": [0.0]}(replace 0.0 with real values)","{'IIF': [0.00022957766970338144], 'IGF': [6.531420796327108e-06], 'GIF': [1.7013274276116187e-05], 'GGF': [6.076624364512684e-07], 'AIF': [1.3747849386984705e-05], 'AGF': [3.417965144382433e-07], 'IID': [0.00012941373053020611], 'IGD': [2.6309788544084347e-06], 'GID': [3.0067999447094528e-05], 'GGD': [1.4998125126298506e-06], 'AID': [2.832898259643734e-05], 'AGD': [1.471852226331411e-06], 'IIR': [3.843119017823239e-06], 'IGR': [8.527492939359041e-07], 'GIR': [1.9274343908753687e-05], 'GGR': [1.6062016369437721e-06], 'AIR': [2.031354493845111e-05], 'AGR': [1.693986814130217e-06]}","0,1,2,3,4,5,6",python src/run_metric.py --ndatapoints 1 --conduct sh --model Pop --age Y
2205.00048,2,"Run the experiment on movielens dataset with BPRMF model, stochastic conduct, using gender as group label, and on 1 datapoint. Return all metrics in format {""IIF"": [0.0], ""IGF"": [0.0], ""GIF"": [0.0], ""GGF"": [0.0], ""AIF"": [0.0], ""AGF"": [0.0], ""IID"": [0.0], ""IGD"": [0.0], ""GID"": [0.0], ""GGD"": [0.0], ""AID"": [0.0], ""AGD"": [0.0], ""IIR"": [0.0], ""IGR"": [0.0], ""GIR"": [0.0], ""GGR"": [0.0], ""AIR"": [0.0], ""AGR"": [0.0]} (replace 0.0 with real values)","{'IIF': [0.00022484007768105817], 'IGF': [3.082074136416555e-06], 'GIF': [9.181278104732387e-07], 'GGF': [7.469683296964291e-08], 'AIF': [7.250710559713114e-07], 'AGF': [6.663700948973803e-08], 'IID': [0.00012968000016872448], 'IGD': [3.569623602862792e-06], 'GID': [8.174601999868197e-06], 'GGD': [8.250136749057006e-07], 'AID': [7.978072339059405e-06], 'AGD': [8.621028003209006e-07], 'IIR': [8.846980678664919e-06], 'IGR': [5.240740702300814e-06], 'GIR': [1.309852303701036e-05], 'GGR': [1.3120803641594582e-06], 'AIR': [1.298541301208657e-05], 'AGR': [1.3593968930682123e-06]}","0,1,2,3,4,5,6",python src/run_metric.py --ndatapoints 1 --model BPRMF --age N
2205.00048,3,"Run the experiment on movielens dataset with BPRMF model, stochastic conduct, using age as group label, and on 1 datapoint. Return all metrics in format {""IIF"": [0.0], ""IGF"": [0.0], ""GIF"": [0.0], ""GGF"": [0.0], ""AIF"": [0.0], ""AGF"": [0.0], ""IID"": [0.0], ""IGD"": [0.0], ""GID"": [0.0], ""GGD"": [0.0], ""AID"": [0.0], ""AGD"": [0.0], ""IIR"": [0.0], ""IGR"": [0.0], ""GIR"": [0.0], ""GGR"": [0.0], ""AIR"": [0.0], ""AGR"": [0.0]} (replace 0.0 with real values)","{'IIF': [0.00022484007768105817], 'IGF': [3.082074136416555e-06], 'GIF': [1.3634435504785814e-06], 'GGF': [7.798720588589249e-08], 'AIF': [7.250710559713114e-07], 'AGF': [6.663700948973803e-08], 'IID': [0.00012968000016872448], 'IGD': [3.569623602862792e-06], 'GID': [8.315038120896211e-06], 'GGD': [9.70671953612065e-07], 'AID': [7.978072339059405e-06], 'AGD': [8.621028003209006e-07], 'IIR': [8.846980678664919e-06], 'IGR': [5.240740702300814e-06], 'GIR': [1.3171213308192974e-05], 'GGR': [1.6067363084913638e-06], 'AIR': [1.298541301208657e-05], 'AGR': [1.3593968930682123e-06]}","0,1,2,3,4,5,6",python src/run_metric.py --ndatapoints 1 --conduct sh --model BPRMF --age Y
2110.03485,0,"Run the main CartoonX experiment with 1 image from given imagenet_sample directory. Return the last distortion loss in this format {""last_distortion_loss"": 0.0}. Replace 0.0 with the actual answer.","{""last_distortion_loss"": 0.0011765058152377605}","0,1,2,3,4",python cartoonx/main.py --imgdir=images/imagenet_sample --logdir=logs/experiment1 --n_images=1
2110.03485,1,"Run the main CartoonX experiment with 1 image from given imagenet_sample directory. Use lambda value for cartoonx as 10. Return the last distortion loss in this format {""last_distortion_loss"": 0.0}. Replace 0.0 with the actual answer.","{""last_distortion_loss"": 0.0009648270206525922}","0,1,2,3,4",python cartoonx/main.py --imgdir=images/imagenet_sample --logdir=logs/experiment1 --n_images=1 --lambda_cartoonx 10
2110.03485,2,"Run the main CartoonX experiment with 1 image from given imagenet_sample directory. Use lambda value for cartoonx as 30. Return the last distortion loss in this format {""last_distortion_loss"": 0.0}. Replace 0.0 with the actual answer.","{""last_distortion_loss"": 0.0013218128588050604}","0,1,2,3,4",python cartoonx/main.py --imgdir=images/imagenet_sample --logdir=logs/experiment1 --n_images=1 --lambda_cartoonx 30
2110.03485,3,"Run the model agnotism experiment with 1 image from imagenet_sample. Use l1lambda for ViT to be 10. Return the last ViT sparsity loss in this format {""last_sparsity_loss"": 0.0}. Replace 0.0 with the actual answer.","{""last_sparsity_loss"": 0.01838984340429306}","0,1,2,3,4",python experiments/model_agnosticism_exp.py --imgdir=images/imagenet_sample --logdir=logs/experiment2 --n_images=1 --lambda_vit=10
2110.03485,4,"Run the model agnotism experiment with 1 image from imagenet_sample. Use l1lambda for ViT to be 20. Return the last ViT sparsity loss in this format {""last_sparsity_loss"": 0.0}. Replace 0.0 with the actual answer.","{""last_sparsity_loss"": 0.03278161212801933}","0,1,2,3,4",python experiments/model_agnosticism_exp.py --imgdir=images/imagenet_sample --logdir=logs/experiment2 --n_images=1 --lambda_vit=20
2110.03485,5,"Run the model agnotism experiment with 1 image from imagenet_sample. Use l1lambda for ViT to be 5. Return the last ViT sparsity loss in this format {""last_sparsity_loss"": 0.0}. Replace 0.0 with the actual answer.","{""last_sparsity_loss"": 0.012362958863377571}","0,1,2,3,4",python experiments/model_agnosticism_exp.py --imgdir=images/imagenet_sample --logdir=logs/experiment2 --n_images=1 --lambda_vit=5