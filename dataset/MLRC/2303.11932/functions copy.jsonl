{"paper_id": "2303.11932", "func_id": "0", "file": "losses.py", "name": "__call__", "header_line": "68", "line_start": "69", "line_end": "88", "relevant_paper": "Energy Pointing Game (EPG) measures the concentration of attribution energy within the mask, the\nfraction of positive attributions inside the bounding boxes:\n$$\\label{eq:epg}\n    \\text{EPG}_k = \\frac{\\sum_{h=1}^H\\sum_{w=1}^W M_{k,hw} A^+_{k,hw}}{\\sum_{h=1}^H\\sum_{w=1}^W A^+_{k,hw}}\\;.$$\n\nIn addition to\nthe losses described in prior work, we propose to also evaluate using\nthe score (, [\\[eq:epg\\]](#eq:epg){reference-type=\"ref\"\nreference=\"eq:epg\"}) as a loss function for model guidance, as it is\nfully differentiable. In particular, we simply define it as\n$$\\label{eq:energyloss}\n\\textstyle\n    \\mathcal{L}_{\\text{loc},k} = -\\text{EPG}_k.$$ Unlike existing\nlocalization losses that either (i) do not constrain attributions across\nthe entire input (, ), or (ii) force the model to attribute uniformly\nwithin the mask even if it includes irrelevant background regions (, ),\nmaximizing the score jointly optimizes for higher attribution energy\nwithin the mask and lower attribution energy outside the mask. By not\nenforcing a uniformity prior, we find that the loss is able to provide\neffective guidance while allowing the model to learn freely what to\nfocus on within the bounding boxes", "description": "Compute the Energy loss based on model attributions and bounding box coordinates.\n\n:param attributions: A tensor containing attributions from the model. Typically, this would be the gradients or some form of saliency map indicating the importance of each input element.\n:param bb_coordinates: A list of tuples representing bounding box coordinates. Each tuple should contain four integers (xmin, ymin, xmax, ymax) specifying the top-left and bottom-right corners of the bounding box.\n\n:modifies: This function initializes and modifies the 'bb_mask', a tensor of the same shape as 'attributions' with the region inside the bounding boxes set to 1 and the rest to 0.\n\n:effects: None. This function does not produce any output effects such as printing or logging.\n\n:return: A float representing the computed energy loss."}
{"paper_id": "2303.11932", "func_id": "1", "file": "losses.py", "name": "__call__", "header_line": "90", "line_start": "91", "line_end": "102", "relevant_paper": "RRR* introduced the RRR loss to regularize the normalized input gradients\n$\\hat{A}_{k,hw}$ as $$\\label{eq:rrr}\n    \\textstyle \\mathcal{L}_{\\text{loc},k} = \\sum_{h=1}^H\\sum_{w=1}^W (1-M_{k,hw}) \\hat{A}_{k,hw}^2 \\;.$$\nTo extend it to our setting, we take $\\hat{A}_{k,hw}$ to be given by an\narbitrary attribution method (); we denote this generalized version by RRR*.\nIn contrast to the loss, only regularizes attributions *outside* the\nground truth masks. While it thus does not introduce a uniformity prior\nsimilar to the loss, it also does not explicitly promote high importance\nattributions inside the masks.", "description": "Calculates the RRR (Remove and Retrain) localization loss given attribution scores and bounding box coordinates.\n\n:param attributions: A tensor containing the attribution scores of each element. Typically, this tensor highlights the importance of each input feature with respect to a model's prediction.\n:param bb_coordinates: A tensor containing the coordinates of the bounding box. These coordinates are used to mask the parts of the attributions that are relevant (inside the bounding box).\n\n:modifies self.only_positive: Initialized to False in the constructor but not modified in this function.\n:modifies self.binarize: Initialized to True in the constructor but not modified in this function.\n\n:return: A scalar tensor representing the sum of squared attribution scores for parts of the input that fall outside the bounding box. This scalar indicates the RRR localization loss, where a lower value suggests that the model's important features align well within the bounding box."}
{"paper_id": "2303.11932", "func_id": "2", "file": "losses.py", "name": "__call__", "header_line": "120", "line_start": "121", "line_end": "133", "relevant_paper": "Per-pixel cross entropy loss (PPCE) applies a binary cross entropy loss between the mask and the normalized\npositive annotations $\\hat A_{k}^+$, thus guiding the model to maximize\nthe attributions inside the mask: $$\\label{eq:ppce}\n\\textstyle\n    \\mathcal{L}_{\\text{loc},k} = -\\frac{1}{\\lVert M_k \\rVert_1}\\sum_{h=1}^H\\sum_{w=1}^W M_{k,hw}\\log(\\hat{A}_{k,hw}^+) \\;.$$\nAs PPCE does not constrain attributions outside the mask, there is no\nexplicit pressure to avoid spurious features.", "description": "Calculates the PPCE localization loss given the attributions and bounding box coordinates. This class uses the Binary Cross Entropy Loss (BCELoss) to compute the loss.\n\n:param attributions: A tensor representing the attributions, which are typically the output of a neural network in the format of gradients or relevance scores.\n:param bb_coordinates: A tensor containing the bounding box coordinates. These coordinates define the area of interest within the attributions that should be considered for loss calculation.\n\n:modifies self.bce_loss: Initializes self.bce_loss to torch.nn.BCELoss with reduction set to 'mean'.\n:modifies self.only_positive: Sets self.only_positive to True, indicating the implementation might be limited to only positive samples.\n:modifies self.binarize: Sets self.binarize to True, which likely relates to binarizing the attribution values or the bounding box effects.\n\n:effects: None\n\n:return: Returns the computed binary cross entropy loss between the attributions inside the bounding box and a tensor of ones with the same size as attributions_in_box. This measures the closeness of the attributions within the bounding box to the target distribution of all ones, representing a perfect match."}
{"paper_id": "2303.11932", "func_id": "3", "file": "losses.py", "name": "__call__", "header_line": "105", "line_start": "106", "line_end": "117", "relevant_paper": "", "description": "Calculates the L1 localization loss between predicted attributions and a binary mask created from bounding box coordinates.\n\n:param attributions: A tensor representing the predicted attributions for a model, in some spatial dimensions.\n:param bb_coordinates: A tensor containing bounding box coordinates used to create a mask that the attributions are compared against.\n:modifies self.l1_loss: Initializes self.l1_loss as an instance of torch.nn.L1Loss with reduction set to 'mean'.\n:modifies self.only_positive: Sets self.only_positive to True during initialization.\n:modifies self.binarize: Sets self.binarize to True during initialization.\n:return: A scalar tensor representing the L1 loss between the attributions and the bounding box mask."}
{"paper_id": "2303.11932", "func_id": "4", "file": "bcos/models/bcos_common.py", "name": "forward_and_explain", "header_line": "64", "line_start": "65", "line_end": "115", "relevant_paper": "", "description": "Performs linear map calculations on a batched image tensor to generate gradient-based explanations.\n\n:param in_tensor: A 4D tensor representing batched images with dimensions [batch_size, channels, height, width].\n:param idx: Optional parameter. Either a list or tensor of indices corresponding to the classes for which explanations are required. If None, explanations are generated for the predicted class.\n:param color_explanations: A boolean indicating whether to generate color-coded gradient explanations. Default is True.\n:param keep_graph: A boolean indicating whether to retain the computation graph for further gradient calculations. Default is False.\n:param kwargs: Additional keyword arguments passed to the `gradient_to_image` method.\n\n:modifies in_tensor.grad: Sets the gradient of `in_tensor` to None initially, then computes and populates it with gradients.\n:effects: None explicitly, but asserts within the function may raise exceptions if conditions are not met.\n:returns: A dictionary with:\n    - \"weight\": Gradients with respect to `in_tensor`.\n    - \"output\": Model predictions for `in_tensor`.\n    - \"idx\": Either provided indices or those of maximum predicted logit.\n    - \"contribution\": Color-coded contributions if `color_explanations` is True, otherwise raw gradients."}
{"paper_id": "2303.11932", "func_id": "5", "file": "bcos/models/bcos_common.py", "name": "gradient_to_image", "header_line": "118", "line_start": "119", "line_end": "149", "relevant_paper": "", "description": "Generates an image-like numpy array representing the contribution of each pixel to the network's output, scaled by an alpha channel for visibility.\n\n:param cls: Implicit class reference, typically used in class methods.\n:param image: A Torch tensor with shape [C, H, W] representing the input image where C is the number of channels, H is the height, and W is the width.\n:param linear_mapping: A Torch tensor with shape [C, H, W] representing the linear mapping for the contribution gradients.\n:param smooth: An integer representing the size of the smoothing kernel to apply using average pooling. Default is 0, indicating no smoothing.\n:param alpha_percentile: A float representing the percentile to normalize the alpha channel, which controls alpha intensity. Default is 99.5.\n\n:returns: A numpy array of shape [H, W, C] where C=4, representing the RGB values and alpha channel, showing the contribution of each gradient pixel.\n\n:modifies: None of the input tensors or class/instance variables.\n\n:effects: Computes transformation and normalization on the input tensors, although it uses intermediate prints or logs, computations may involve side effects like small numerical inaccuracies due to tensor operations."}
{"paper_id": "2303.11932", "func_id": "6", "file": "metrics.py", "name": "compute", "header_line": "34", "line_start": "35", "line_end": "41", "relevant_paper": "", "description": "Calculates the mean of a list of fractions based on certain conditions.\n\n:modifies: None\n\n:effects: None\n\n:return: \n    - None if `self.fractions` is empty or if `self.include_undefined` is False and `self.defined_idxs` is empty.\n    - If `self.include_undefined` is True, returns the floating-point mean of all values in `self.fractions`.\n    - Otherwise, returns the floating-point mean of the values at indices specified in `self.defined_idxs` within `self.fractions`."}
{"paper_id": "2303.11932", "func_id": "7", "file": "metrics.py", "name": "update", "header_line": "61", "line_start": "62", "line_end": "90", "relevant_paper": "", "description": "Updates the metric based on the provided attributions and bounding box coordinates.\n\nThis function modifies several class variables by appending values calculated \nfrom the input tensors, and it uses these values to update the state of the metric.\n\nArgs:\n    attributions (tensor): A tensor representing model attributions, where the \n        positive values indicate the relevance of features.\n    bb_coordinates (list of tuples): A list of tuples, each representing the \n        coordinates of a bounding box in the form (xmin, ymin, xmax, ymax).\n\nModifies:\n    self.fractions: Appends the ratio of the energy inside the bounding box \n        to the total energy when the total energy is significant.\n    self.bbox_sizes: Appends the size of the bounding box if the size constraints are met.\n    self.defined_idxs: Appends the index of the newly calculated fraction when \n        the total energy is significant.\n\nEffects:\n    This function does not produce any direct effects like print statements or \n    external state changes, other than the modification of class variables.\n\nReturn:\n    None. The function returns early if the bounding box size does not meet \n    specified minimum or maximum size constraints."}
{"paper_id": "2303.11932", "func_id": "8", "file": "metrics.py", "name": "update", "header_line": "170", "line_start": "171", "line_end": "192", "relevant_paper": "", "description": "Processes the attributions to calculate and append fractional intersection over union (IoU) scores for bounding boxes.\n\n:param attributions: A torch tensor representing the attribute scores for each point in the image.\n:param bb_coordinates: A list of tuples/lists where each entry represents the bounding box coordinates \n                       as (xmin, ymin, xmax, ymax).\n:modifies: \n    - self.fractions: Appends the calculated IoU fraction to the list.\n    - self.defined_idxs: Appends the index of the newly added fraction if the union_area is not zero.\n\n:effects: None.\n\n:returns: None. The function returns early if the bounding box size does not meet defined constraints.\n\nAdditional notes:\n- The function computes the positive attributions by clamping the input attributions with a minimum value of 0.\n- Constructs a bounding box mask (`bb_mask`) for provided bounding box coordinates.\n- Calculates the size of the bounding box (`bb_size`).\n- The function returns early if the `bb_size` is smaller than `self.min_box_size` or larger than or equal to `self.max_box_size`, if such limits are defined.\n- Utilizes a binarized version of the positive attributions to compute the intersection and union areas with the bounding box mask using the IoU threshold.\n- If union_area is zero, appends 0.0 to `self.fractions`. Otherwise, calculates the fraction of intersection area over union_area and appends this to `self.fractions`."}
{"paper_id": "2303.11932", "func_id": "9", "file": "attribution_methods.py", "name": "_call_batch_mode", "header_line": "175", "line_start": "176", "line_end": "181", "relevant_paper": "B-cos attributions are generated using the inherently-interpretable networks,\nwhich promote alignment between the input $\\mathbf x$ and a dynamic\nweight matrix $\\mathbf W(\\mathbf x)$ during optimization. In our\nexperiments, we use the contribution maps given by the element-wise\nproduct of the dynamic weights with the input\n($\\mathbf W^T_k(\\mathbf x)\\odot \\mathbf x$), which faithfully represent\nthe contribution of each pixel to class $k$. To be able to guide models,\nwe developed a differentiable implementation of explanations, see\nsupplement.", "description": "Computes attributions of model outputs with respect to input features and applies post-processing.\n\n:param output: A tensor representing the model output.\n:param classes: A tensor containing class indices for which to gather outputs.\n:param feature: A tensor of input features with respect to which the gradients are computed and attributions are derived.\n:modifies: None, although it temporarily switches the model to explanation mode within the context manager.\n:effects: None\n:return: A tensor representing the post-processed attributions of the model's outputs with respect to the input features. The attributions are derived by weighing the gradients of the target outputs with the input features, and then summing along the specified dimensions."}
{"paper_id": "2303.11932", "func_id": "10", "file": "attribution_methods.py", "name": "_call_single", "header_line": "183", "line_start": "184", "line_end": "189", "relevant_paper": "B-cos attributions are generated using the inherently-interpretable networks,\nwhich promote alignment between the input $\\mathbf x$ and a dynamic\nweight matrix $\\mathbf W(\\mathbf x)$ during optimization. In our\nexperiments, we use the contribution maps given by the element-wise\nproduct of the dynamic weights with the input\n($\\mathbf W^T_k(\\mathbf x)\\odot \\mathbf x$), which faithfully represent\nthe contribution of each pixel to class $k$. To be able to guide models,\nwe developed a differentiable implementation of explanations, see\nsupplement.", "description": "Computes gradient-based attributions for a specific class and image index using a feature tensor and applies post-processing.\n\n:modifies: Utilizes a context manager `self.model.explanation_mode()` to modify the model's state for explanation purposes.\n:param output: A tensor representing the model's output, typically of shape (batch_size, num_classes).\n:param img_idx: An integer indicating the index of the image in the batch whose gradient is to be computed.\n:param class_idx: An integer specifying the class index for which the gradient is being computed.\n:param feature: A tensor representing the feature of interest from which gradients will be computed.\n:effects: Calculates the gradient of the specified class output with respect to the specified feature.\n:return: A tensor representing the post-processed attributions, achieved by element-wise multiplication of the gradients and feature tensor, summed along a specified dimension (dim=0) and unsqueezed for added dimension."}
{"paper_id": "2303.11932", "func_id": "11", "file": "attribution_methods.py", "name": "_call_batch_mode", "header_line": "198", "line_start": "199", "line_end": "206", "relevant_paper": "GradCam computes importance attributions as a ReLU-thresholded,\ngradient-weighted sum of activation maps. In detail, it is given by\n$\\text{ReLU}(\\sum_c \\alpha_c^k \\odot U_c)$ with $c$ denoting the channel\ndimension, and $\\alpha^k$ the average-pooled gradients of the output for\nclass $k$ with respect to the activations $U$ of the last convolutional\nlayer in the model.", "description": "Computes attributions for feature importance based on gradients and returns the post-processed attributions.\n\n:param output: Tensor of model outputs from which to gather target outputs based on the specified classes.\n:param classes: Tensor specifying which class indices to use for gathering target outputs.\n    It is expected to match the batch size of the output tensor.\n:param feature: Tensor representing the features for which the importance is being calculated.\n\n:effects: This function involves operations for calculating gradients and handles tensors in PyTorch, but does not produce any direct side effects such as modifying globals or printing.\n\n:return: A tensor containing the post-processed attributions indicating the importance of each feature with respect to the specified classes."}
{"paper_id": "2303.11932", "func_id": "12", "file": "attribution_methods.py", "name": "_call_single", "header_line": "208", "line_start": "209", "line_end": "215", "relevant_paper": "GradCam computes importance attributions as a ReLU-thresholded,\ngradient-weighted sum of activation maps. In detail, it is given by\n$\\text{ReLU}(\\sum_c \\alpha_c^k \\odot U_c)$ with $c$ denoting the channel\ndimension, and $\\alpha^k$ the average-pooled gradients of the output for\nclass $k$ with respect to the activations $U$ of the last convolutional\nlayer in the model.", "description": "Calculates the attribution of features for a specific class index in a given image using gradient-based saliency mapping.\n\n:param output: A tensor representing the model's output where gradients will be computed. It is assumed to have dimensions including batch size, class index, etc.\n:param img_idx: The index of the image in the batch for which the attributions are being computed.\n:param class_idx: The class index in the output tensor for which the feature attribution is being calculated.\n:param feature: A tensor representing the features of the model for which attributions will be calculated, typically obtained from an intermediate layer.\n\n:effects: This function does not produce any print statements or other side effects.\n\n:return: The function returns a tensor containing the processed attributions for the specified image and class index. The output is of the same type as the input tensor and is passed through a post-processing function `self.apply_post_processing`."}
{"paper_id": "2303.11932", "func_id": "13", "file": "attribution_methods.py", "name": "_call_batch_mode", "header_line": "224", "line_start": "225", "line_end": "229", "relevant_paper": "IxG computes the element-wise product $\\odot$ of the input and the gradients\nof the $k$-th output w.r.t.\u00a0the input, $X\\odot\\nabla_X f_k(X)$. For\npiece-wise linear models such as DNNs with ReLU activations , this\nfaithfully computes the linear contributions of a given input pixel to\nthe model output.", "description": "Computes and returns the attributions for given features and outputs using gradients.\n\nThe function performs the following operations:\n1. Gathers the target outputs from the provided output tensor using the indices specified in the classes tensor.\n2. Computes the gradients of these target outputs with respect to the provided features.\n3. Calculates the attributions by element-wise multiplying the gradients with the features and summing along the specified dimension.\n4. Applies post-processing to the computed attributions before returning them.\n\n:param output: A PyTorch tensor representing the model's output from which target outputs are gathered.\n:param classes: A PyTorch tensor containing class indices used to gather target outputs from the output tensor.\n:param feature: A PyTorch tensor containing the input features with respect to which the gradients are computed.\n\n:modifies: No global or class variables are directly modified in this function.\n\n:effects: This function calls external functions such as `torch.gather`, `torch.autograd.grad`, and `self.apply_post_processing`.\n\n:return: A PyTorch tensor representing the post-processed attributions."}
{"paper_id": "2303.11932", "func_id": "14", "file": "attribution_methods.py", "name": "_call_single", "header_line": "231", "line_start": "232", "line_end": "236", "relevant_paper": "IxG computes the element-wise product $\\odot$ of the input and the gradients\nof the $k$-th output w.r.t.\u00a0the input, $X\\odot\\nabla_X f_k(X)$. For\npiece-wise linear models such as DNNs with ReLU activations , this\nfaithfully computes the linear contributions of a given input pixel to\nthe model output.", "description": "Computes the gradients of the given class output with respect to the specified feature and returns the processed attributions.\n\n:modifies grads: Stores the gradients of the output with respect to the feature.\n:modifies attributions: Contains the computed attributions by element-wise multiplication of gradients and the feature, summed along a specified dimension.\n:effects: No direct effects like print statements are present.\n:return: The processed attributions after applying post-processing.\n:param output: A tensor representing the model's output from which gradients are computed. It is expected to have dimensions that allow indexing with img_idx and class_idx.\n:param img_idx: An integer denoting the index of the specific image in the batch.\n:param class_idx: An integer denoting the index of the specific class for which gradients are computed.\n:param feature: A tensor with respect to which the gradients are computed. It is expected to be aligned with the output dimensions for gradient calculation."}
