{"paper_id": "2303.11932", "func_id": "0", "file": "losses.py", "name": "__call__", "header_line": "68", "line_start": "69", "line_end": "88", "relevant_paper": "Energy Pointing Game (EPG) measures the concentration of attribution energy within the mask, the\nfraction of positive attributions inside the bounding boxes:\n$$\\label{eq:epg}\n    \\text{EPG}_k = \\frac{\\sum_{h=1}^H\\sum_{w=1}^W M_{k,hw} A^+_{k,hw}}{\\sum_{h=1}^H\\sum_{w=1}^W A^+_{k,hw}}\\;.$$\n\nIn addition to\nthe losses described in prior work, we propose to also evaluate using\nthe score (, [\\[eq:epg\\]](#eq:epg){reference-type=\"ref\"\nreference=\"eq:epg\"}) as a loss function for model guidance, as it is\nfully differentiable. In particular, we simply define it as\n$$\\label{eq:energyloss}\n\\textstyle\n    \\mathcal{L}_{\\text{loc},k} = -\\text{EPG}_k.$$ Unlike existing\nlocalization losses that either (i) do not constrain attributions across\nthe entire input (, ), or (ii) force the model to attribute uniformly\nwithin the mask even if it includes irrelevant background regions (, ),\nmaximizing the score jointly optimizes for higher attribution energy\nwithin the mask and lower attribution energy outside the mask. By not\nenforcing a uniformity prior, we find that the loss is able to provide\neffective guidance while allowing the model to learn freely what to\nfocus on within the bounding boxes", "description": "Compute the Energy loss based on model attributions and bounding box coordinates.\n\n:param attributions: A tensor containing attributions from the model. \n:param bb_coordinates: A list of tuples representing bounding box coordinates. Each tuple should contain four integers (xmin, ymin, xmax, ymax) specifying the top-left and bottom-right corners of the bounding box.\n\n:return: A float representing the computed energy loss."}
{"paper_id": "2303.11932", "func_id": "1", "file": "losses.py", "name": "__call__", "header_line": "90", "line_start": "91", "line_end": "102", "relevant_paper": "RRR* introduced the RRR loss to regularize the normalized input gradients\n$\\hat{A}_{k,hw}$ as $$\\label{eq:rrr}\n    \\textstyle \\mathcal{L}_{\\text{loc},k} = \\sum_{h=1}^H\\sum_{w=1}^W (1-M_{k,hw}) \\hat{A}_{k,hw}^2 \\;.$$\nTo extend it to our setting, we take $\\hat{A}_{k,hw}$ to be given by an\narbitrary attribution method (); we denote this generalized version by RRR*.\nIn contrast to the loss, only regularizes attributions *outside* the\nground truth masks. While it thus does not introduce a uniformity prior\nsimilar to the loss, it also does not explicitly promote high importance\nattributions inside the masks.", "description": "Calculates the RRR (Remove and Retrain) localization loss given attribution scores and bounding box coordinates.\n\n:param attributions: A tensor containing the attribution scores of each element. Typically, this tensor highlights the importance of each input feature with respect to a model's prediction.\n:param bb_coordinates: A tensor containing the coordinates of the bounding box. These coordinates are used to mask the parts of the attributions that are relevant (inside the bounding box).\n\n:modifies self.only_positive: Initialized to False in the constructor but not modified in this function.\n:modifies self.binarize: Initialized to True in the constructor but not modified in this function.\n\n:return: A scalar tensor"}
{"paper_id": "2303.11932", "func_id": "2", "file": "losses.py", "name": "__call__", "header_line": "120", "line_start": "121", "line_end": "133", "relevant_paper": "Per-pixel cross entropy loss (PPCE) applies a binary cross entropy loss between the mask and the normalized\npositive annotations $\\hat A_{k}^+$, thus guiding the model to maximize\nthe attributions inside the mask: $$\\label{eq:ppce}\n\\textstyle\n    \\mathcal{L}_{\\text{loc},k} = -\\frac{1}{\\lVert M_k \\rVert_1}\\sum_{h=1}^H\\sum_{w=1}^W M_{k,hw}\\log(\\hat{A}_{k,hw}^+) \\;.$$\nAs PPCE does not constrain attributions outside the mask, there is no\nexplicit pressure to avoid spurious features.", "description": "Calculates the PPCE localization loss given the attributions and bounding box coordinates. This class uses the Binary Cross Entropy Loss (BCELoss) to compute the loss.\n\n:param attributions: A tensor representing the attributions\n:param bb_coordinates: A tensor containing the bounding box coordinates. \n\n:return: Returns the computed binary cross entropy loss between the attributions inside the bounding box and a tensor of ones with the same size as attributions_in_box. This measures the closeness of the attributions within the bounding box to the target distribution of all ones, representing a perfect match."}
{"paper_id": "2303.11932", "func_id": "3", "file": "losses.py", "name": "__call__", "header_line": "105", "line_start": "106", "line_end": "117", "relevant_paper": "", "description": "Calculates the L1 localization loss between predicted attributions and a binary mask created from bounding box coordinates.\n\n:param attributions: A tensor representing the predicted attributions for a model, in some spatial dimensions.\n:param bb_coordinates: A tensor containing bounding box coordinates\n\n:return: A scalar tensor representing the L1 loss"}
{"paper_id": "2303.11932", "func_id": "4", "file": "bcos/models/bcos_common.py", "name": "forward_and_explain", "header_line": "64", "line_start": "65", "line_end": "115", "relevant_paper": "", "description": "Performs linear map calculations on a batched image tensor to generate gradient-based explanations.\n\n:param in_tensor: A 4D tensor representing batched images with dimensions [batch_size, channels, height, width].\n:param idx: Optional parameter. Either a list or tensor of indices \n:param color_explanations: A boolean indicating whether to generate color-coded gradient explanations. Default is True.\n:param keep_graph: A boolean indicating whether to retain the computation graph for further gradient calculations. Default is False.\n:param kwargs\n\n:returns: A dictionary with:\n    - \"weight\"\n    - \"output\"\n    - \"idx\" \n- \"contribution\": Color-coded contributions if `color_explanations` is True, otherwise raw gradients."}
{"paper_id": "2303.11932", "func_id": "5", "file": "bcos/models/bcos_common.py", "name": "gradient_to_image", "header_line": "118", "line_start": "119", "line_end": "149", "relevant_paper": "", "description": "Generates an image-like numpy array representing the contribution of each pixel to the network's output, scaled by an alpha channel for visibility.\n\n:param cls: Implicit class reference, typically used in class methods.\n:param image: A Torch tensor with shape [C, H, W] representing the input image where C is the number of channels, H is the height, and W is the width.\n:param linear_mapping: A Torch tensor with shape [C, H, W] representing the linear mapping for the contribution gradients.\n:param smooth: An integer \n:param alpha_percentile: A float \n\n:returns: A numpy array of shape [H, W, C]"}
{"paper_id": "2303.11932", "func_id": "6", "file": "metrics.py", "name": "compute", "header_line": "34", "line_start": "35", "line_end": "41", "relevant_paper": "", "description": "Calculates the mean of a list of fractions based on certain conditions.\n\n:return: float"}
{"paper_id": "2303.11932", "func_id": "7", "file": "metrics.py", "name": "update", "header_line": "61", "line_start": "62", "line_end": "90", "relevant_paper": "", "description": "Updates the metric based on the provided attributions and bounding box coordinates.\n\nArgs:\n    attributions (tensor): A tensor representing model attributions\n    bb_coordinates (list of tuples): A list of tuples, each representing the coordinates of a bounding box in the form (xmin, ymin, xmax, ymax).\n\nReturn:tensor"}
{"paper_id": "2303.11932", "func_id": "8", "file": "metrics.py", "name": "update", "header_line": "170", "line_start": "171", "line_end": "192", "relevant_paper": "", "description": "Processes the attributions to calculate and append fractional intersection over union (IoU) scores for bounding boxes.\n\n:param attributions: A torch tensor representing the attribute scores for each point in the image.\n:param bb_coordinates: A list of tuples/lists where each entry represents the bounding box coordinates \n                       as (xmin, ymin, xmax, ymax).\n:modifies: \n    - self.fractions: Appends the calculated IoU fraction to the list.\n    - self.defined_idxs: Appends the index of the newly added fraction if the union_area is not zero.\n\n:returns: tensor"}
{"paper_id": "2303.11932", "func_id": "9", "file": "attribution_methods.py", "name": "_call_batch_mode", "header_line": "175", "line_start": "176", "line_end": "181", "relevant_paper": "B-cos attributions are generated using the inherently-interpretable networks,\nwhich promote alignment between the input $\\mathbf x$ and a dynamic\nweight matrix $\\mathbf W(\\mathbf x)$ during optimization. In our\nexperiments, we use the contribution maps given by the element-wise\nproduct of the dynamic weights with the input\n($\\mathbf W^T_k(\\mathbf x)\\odot \\mathbf x$), which faithfully represent\nthe contribution of each pixel to class $k$. To be able to guide models,\nwe developed a differentiable implementation of explanations, see\nsupplement.", "description": "Computes attributions of model outputs with respect to input features and applies post-processing.\n\n:param output: A tensor representing the model output.\n:param classes: A tensor containing class indices for which to gather outputs.\n:param feature: A tensor of input features with respect to which the gradients are computed and attributions are derived.\n:return: A tensor representing the post-processed attributions of the model's outputs with respect to the input features."}
{"paper_id": "2303.11932", "func_id": "10", "file": "attribution_methods.py", "name": "_call_single", "header_line": "183", "line_start": "184", "line_end": "189", "relevant_paper": "B-cos attributions are generated using the inherently-interpretable networks,\nwhich promote alignment between the input $\\mathbf x$ and a dynamic\nweight matrix $\\mathbf W(\\mathbf x)$ during optimization. In our\nexperiments, we use the contribution maps given by the element-wise\nproduct of the dynamic weights with the input\n($\\mathbf W^T_k(\\mathbf x)\\odot \\mathbf x$), which faithfully represent\nthe contribution of each pixel to class $k$. To be able to guide models,\nwe developed a differentiable implementation of explanations, see\nsupplement.", "description": "Computes gradient-based attributions for a specific class and image index using a feature tensor and applies post-processing.\n\n:param output: A tensor representing the model's output, typically of shape (batch_size, num_classes).\n:param img_idx: An integer indicating the index of the image in the batch whose gradient is to be computed.\n:param class_idx: An integer specifying the class index for which the gradient is being computed.\n:param feature: A tensor representing the feature of interest from which gradients will be computed.\nreturn: A tensor representing the post-processed attributions"}
{"paper_id": "2303.11932", "func_id": "11", "file": "attribution_methods.py", "name": "_call_batch_mode", "header_line": "198", "line_start": "199", "line_end": "206", "relevant_paper": "GradCam computes importance attributions as a ReLU-thresholded,\ngradient-weighted sum of activation maps. In detail, it is given by\n$\\text{ReLU}(\\sum_c \\alpha_c^k \\odot U_c)$ with $c$ denoting the channel\ndimension, and $\\alpha^k$ the average-pooled gradients of the output for\nclass $k$ with respect to the activations $U$ of the last convolutional\nlayer in the model.", "description": "Computes attributions for feature importance based on gradients and returns the post-processed attributions.\n\n:param output: Tensor of model outputs from which to gather target outputs based on the specified classes.\n:param classes: Tensor specifying which class indices to use for gathering target outputs.\n    It is expected to match the batch size of the output tensor.\n:param feature: Tensor representing the features for which the importance is being calculated.\n\n:return: A tensor containing the post-processed attributions"}
{"paper_id": "2303.11932", "func_id": "12", "file": "attribution_methods.py", "name": "_call_single", "header_line": "208", "line_start": "209", "line_end": "215", "relevant_paper": "GradCam computes importance attributions as a ReLU-thresholded,\ngradient-weighted sum of activation maps. In detail, it is given by\n$\\text{ReLU}(\\sum_c \\alpha_c^k \\odot U_c)$ with $c$ denoting the channel\ndimension, and $\\alpha^k$ the average-pooled gradients of the output for\nclass $k$ with respect to the activations $U$ of the last convolutional\nlayer in the model.", "description": "Calculates the attribution of features for a specific class index in a given image using gradient-based saliency mapping.\n\n:param output: A tensor representing the model's output where gradients will be computed. It is assumed to have dimensions including batch size, class index, etc.\n:param img_idx: The index of the image in the batch for which the attributions are being computed.\n:param class_idx: The class index in the output tensor for which the feature attribution is being calculated.\n:param feature: A tensor representing the features of the model for which attributions will be calculated\n\n:return: The function returns a tensor containing the processed attributions for the specified image and class index."}
{"paper_id": "2303.11932", "func_id": "13", "file": "attribution_methods.py", "name": "_call_batch_mode", "header_line": "224", "line_start": "225", "line_end": "229", "relevant_paper": "IxG computes the element-wise product $\\odot$ of the input and the gradients\nof the $k$-th output w.r.t.\u00a0the input, $X\\odot\\nabla_X f_k(X)$. For\npiece-wise linear models such as DNNs with ReLU activations , this\nfaithfully computes the linear contributions of a given input pixel to\nthe model output.", "description": "Computes and returns the attributions for given features and outputs using gradients.\n\nThe function performs the following operations:\n1. Gathers the target outputs from the provided output tensor using the indices specified in the classes tensor.\n2. Computes the gradients of these target outputs with respect to the provided features.\n3. Calculates the attributions by element-wise multiplying the gradients with the features and summing along the specified dimension.\n4. Applies post-processing to the computed attributions before returning them.\n\n:param output: A PyTorch tensor representing the model's output from which target outputs are gathered.\n:param classes: A PyTorch tensor containing class indices used to gather target outputs from the output tensor.\n:param feature: A PyTorch tensor containing the input features with respect to which the gradients are computed.\n\n:return: A PyTorch tensor representing the post-processed attributions."}
{"paper_id": "2303.11932", "func_id": "14", "file": "attribution_methods.py", "name": "_call_single", "header_line": "231", "line_start": "232", "line_end": "236", "relevant_paper": "IxG computes the element-wise product $\\odot$ of the input and the gradients\nof the $k$-th output w.r.t.\u00a0the input, $X\\odot\\nabla_X f_k(X)$. For\npiece-wise linear models such as DNNs with ReLU activations , this\nfaithfully computes the linear contributions of a given input pixel to\nthe model output.", "description": "Computes the gradients of the given class output with respect to the specified feature and returns the processed attributions.\n\n:modifies grads: Stores the gradients of the output with respect to the feature.\n:modifies attributions: Contains the computed attributions by element-wise multiplication of gradients and the feature, summed along a specified dimension.\n:effects: No direct effects like print statements are present.\n:return: The processed attributions after applying post-processing.\n:param output: A tensor representing the model's output from which gradients are computed. It is expected to have dimensions that allow indexing with img_idx and class_idx.\n:param img_idx: An integer denoting the index of the specific image in the batch.\n:param class_idx: An integer denoting the index of the specific class for which gradients are computed.\n:param feature: A tensor with respect to which the gradients are computed. It is expected to be aligned with the output dimensions for gradient calculation."}
