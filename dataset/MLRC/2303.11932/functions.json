{"functions": [{"paper_id": "2303.11932", "func_id": "0", "file": "losses.py", "name": "__call__", "header_line": "68", "line_start": "69", "line_end": "88", "relevant_paper": "Energy Pointing Game (EPG) measures the concentration of attribution energy within the mask, the\nfraction of positive attributions inside the bounding boxes:\n$$\\label{eq:epg}\n    \\text{EPG}_k = \\frac{\\sum_{h=1}^H\\sum_{w=1}^W M_{k,hw} A^+_{k,hw}}{\\sum_{h=1}^H\\sum_{w=1}^W A^+_{k,hw}}\\;.$$\n\nIn addition to\nthe losses described in prior work, we propose to also evaluate using\nthe score (, [\\[eq:epg\\]](#eq:epg){reference-type=\"ref\"\nreference=\"eq:epg\"}) as a loss function for model guidance, as it is\nfully differentiable. In particular, we simply define it as\n$$\\label{eq:energyloss}\n\\textstyle\n    \\mathcal{L}_{\\text{loc},k} = -\\text{EPG}_k.$$ Unlike existing\nlocalization losses that either (i) do not constrain attributions across\nthe entire input (, ), or (ii) force the model to attribute uniformly\nwithin the mask even if it includes irrelevant background regions (, ),\nmaximizing the score jointly optimizes for higher attribution energy\nwithin the mask and lower attribution energy outside the mask. By not\nenforcing a uniformity prior, we find that the loss is able to provide\neffective guidance while allowing the model to learn freely what to\nfocus on within the bounding boxes"}, {"paper_id": "2303.11932", "func_id": "1", "file": "losses.py", "name": "__call__", "header_line": "90", "line_start": "91", "line_end": "102", "relevant_paper": "RRR* introduced the RRR loss to regularize the normalized input gradients\n$\\hat{A}_{k,hw}$ as $$\\label{eq:rrr}\n    \\textstyle \\mathcal{L}_{\\text{loc},k} = \\sum_{h=1}^H\\sum_{w=1}^W (1-M_{k,hw}) \\hat{A}_{k,hw}^2 \\;.$$\nTo extend it to our setting, we take $\\hat{A}_{k,hw}$ to be given by an\narbitrary attribution method (); we denote this generalized version by RRR*.\nIn contrast to the loss, only regularizes attributions *outside* the\nground truth masks. While it thus does not introduce a uniformity prior\nsimilar to the loss, it also does not explicitly promote high importance\nattributions inside the masks."}, {"paper_id": "2303.11932", "func_id": "2", "file": "losses.py", "name": "__call__", "header_line": "120", "line_start": "121", "line_end": "133", "relevant_paper": "Per-pixel cross entropy loss (PPCE) applies a binary cross entropy loss between the mask and the normalized\npositive annotations $\\hat A_{k}^+$, thus guiding the model to maximize\nthe attributions inside the mask: $$\\label{eq:ppce}\n\\textstyle\n    \\mathcal{L}_{\\text{loc},k} = -\\frac{1}{\\lVert M_k \\rVert_1}\\sum_{h=1}^H\\sum_{w=1}^W M_{k,hw}\\log(\\hat{A}_{k,hw}^+) \\;.$$\nAs PPCE does not constrain attributions outside the mask, there is no\nexplicit pressure to avoid spurious features."}, {"paper_id": "2303.11932", "func_id": "3", "file": "losses.py", "name": "__call__", "header_line": "105", "line_start": "106", "line_end": "117", "relevant_paper": ""}, {"paper_id": "2303.11932", "func_id": "4", "file": "bcos/models/bcos_common.py", "name": "forward_and_explain", "header_line": "64", "line_start": "65", "line_end": "115", "relevant_paper": ""}, {"paper_id": "2303.11932", "func_id": "5", "file": "bcos/models/bcos_common.py", "name": "gradient_to_image", "header_line": "118", "line_start": "119", "line_end": "149", "relevant_paper": ""}, {"paper_id": "2303.11932", "func_id": "6", "file": "metrics.py", "name": "compute", "header_line": "34", "line_start": "35", "line_end": "41", "relevant_paper": ""}, {"paper_id": "2303.11932", "func_id": "7", "file": "metrics.py", "name": "update", "header_line": "61", "line_start": "62", "line_end": "90", "relevant_paper": ""}, {"paper_id": "2303.11932", "func_id": "8", "file": "metrics.py", "name": "update", "header_line": "170", "line_start": "171", "line_end": "192", "relevant_paper": ""}, {"paper_id": "2303.11932", "func_id": "9", "file": "attribution_methods.py", "name": "_call_batch_mode", "header_line": "175", "line_start": "176", "line_end": "181", "relevant_paper": "B-cos attributions are generated using the inherently-interpretable networks,\nwhich promote alignment between the input $\\mathbf x$ and a dynamic\nweight matrix $\\mathbf W(\\mathbf x)$ during optimization. In our\nexperiments, we use the contribution maps given by the element-wise\nproduct of the dynamic weights with the input\n($\\mathbf W^T_k(\\mathbf x)\\odot \\mathbf x$), which faithfully represent\nthe contribution of each pixel to class $k$. To be able to guide models,\nwe developed a differentiable implementation of explanations, see\nsupplement."}, {"paper_id": "2303.11932", "func_id": "10", "file": "attribution_methods.py", "name": "_call_single", "header_line": "183", "line_start": "184", "line_end": "189", "relevant_paper": "B-cos attributions are generated using the inherently-interpretable networks,\nwhich promote alignment between the input $\\mathbf x$ and a dynamic\nweight matrix $\\mathbf W(\\mathbf x)$ during optimization. In our\nexperiments, we use the contribution maps given by the element-wise\nproduct of the dynamic weights with the input\n($\\mathbf W^T_k(\\mathbf x)\\odot \\mathbf x$), which faithfully represent\nthe contribution of each pixel to class $k$. To be able to guide models,\nwe developed a differentiable implementation of explanations, see\nsupplement."}, {"paper_id": "2303.11932", "func_id": "11", "file": "attribution_methods.py", "name": "_call_batch_mode", "header_line": "198", "line_start": "199", "line_end": "206", "relevant_paper": "GradCam computes importance attributions as a ReLU-thresholded,\ngradient-weighted sum of activation maps. In detail, it is given by\n$\\text{ReLU}(\\sum_c \\alpha_c^k \\odot U_c)$ with $c$ denoting the channel\ndimension, and $\\alpha^k$ the average-pooled gradients of the output for\nclass $k$ with respect to the activations $U$ of the last convolutional\nlayer in the model."}, {"paper_id": "2303.11932", "func_id": "12", "file": "attribution_methods.py", "name": "_call_single", "header_line": "208", "line_start": "209", "line_end": "215", "relevant_paper": "GradCam computes importance attributions as a ReLU-thresholded,\ngradient-weighted sum of activation maps. In detail, it is given by\n$\\text{ReLU}(\\sum_c \\alpha_c^k \\odot U_c)$ with $c$ denoting the channel\ndimension, and $\\alpha^k$ the average-pooled gradients of the output for\nclass $k$ with respect to the activations $U$ of the last convolutional\nlayer in the model."}, {"paper_id": "2303.11932", "func_id": "13", "file": "attribution_methods.py", "name": "_call_batch_mode", "header_line": "224", "line_start": "225", "line_end": "229", "relevant_paper": "IxG computes the element-wise product $\\odot$ of the input and the gradients\nof the $k$-th output w.r.t.\u00a0the input, $X\\odot\\nabla_X f_k(X)$. For\npiece-wise linear models such as DNNs with ReLU activations , this\nfaithfully computes the linear contributions of a given input pixel to\nthe model output."}, {"paper_id": "2303.11932", "func_id": "14", "file": "attribution_methods.py", "name": "_call_single", "header_line": "231", "line_start": "232", "line_end": "236", "relevant_paper": "IxG computes the element-wise product $\\odot$ of the input and the gradients\nof the $k$-th output w.r.t.\u00a0the input, $X\\odot\\nabla_X f_k(X)$. For\npiece-wise linear models such as DNNs with ReLU activations , this\nfaithfully computes the linear contributions of a given input pixel to\nthe model output."}]}